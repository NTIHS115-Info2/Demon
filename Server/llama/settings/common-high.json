{
  "modelPath": "E:/ai-training/Demon/Server/llama/model/gemma-3-4b-it-q4_0.gguf",
  "params": {
    "ctx-size": 6144,         
    "n-gpu-layers": 35,
    "threads": 16,
    "batch-size": 256,
    "mirostat": 1,
    "mirostat-lr": 0.1,
    "mirostat-ent": 5.0,
    "repeat_penalty": 1.1,
    "top_p": 0.9,
    "top_k": 40,
    "temp": 0.7,
    "no-mmap": true,
    "port" : 8011
  }
}
