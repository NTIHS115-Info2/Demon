import argparse
import whisper
import sounddevice as sd
import numpy as np
import queue
import json
import webrtcvad
import sys
import torch
import os
import logging
from datetime import datetime
import time

# å‘½ä»¤åˆ—åƒæ•¸è§£æ
parser = argparse.ArgumentParser(description="Whisper å³æ™‚èªéŸ³è¾¨è­˜")
parser.add_argument("--device-name", type=str, default="USBéº¥å…‹é¢¨" , help="è¼¸å…¥è£ç½®åç¨±é—œéµå­—ï¼ˆä¾‹å¦‚ 'microphone'ï¼‰")
parser.add_argument("--device-id", type=int, help="éŸ³è¨Šè¼¸å…¥è£ç½® ID")
parser.add_argument("--use-cpu", action="store_true", help="å¼·åˆ¶ä½¿ç”¨ CPU è€Œé GPU")
parser.add_argument("--blacklist", type=str, default="", help="ä»¥é€—è™Ÿåˆ†éš”çš„é»‘åå–®é—œéµè©")
parser.add_argument("--model", type=str, default="large-v3", help="Whisper æ¨¡å‹åç¨±ï¼ˆå¦‚ tiny, base, small, large-v3ï¼‰")
parser.add_argument("--log-path", type=str, default="asr_log.txt", help="è¼¸å‡º log æª”æ¡ˆè·¯å¾‘")
parser.add_argument("--slice-duration", type=float, default=4.0, help="åˆ‡ç‰‡éŒ„éŸ³é•·åº¦ (ç§’)")
args = parser.parse_args()

# å¦‚æœæŒ‡å®šäº†åç¨±ï¼Œæ ¹æ“šåç¨±æ‰¾ device_id
if args.device_name:
    device_name_lc = args.device_name.lower()
    matched_devices = [
        (i, dev['name']) for i, dev in enumerate(sd.query_devices())
        if dev['max_input_channels'] > 0 and device_name_lc in dev['name'].lower()
    ]
    if not matched_devices:
        print(f"âŒ æ‰¾ä¸åˆ°ç¬¦åˆåç¨± '{args.device_name}' çš„éŸ³è¨Šè¼¸å…¥è£ç½®")
        print("ğŸ§© æç¤ºï¼šä½ å¯ä»¥ä½¿ç”¨ --device-id -1 æŸ¥çœ‹æ‰€æœ‰è£ç½®")
        sys.exit(1)
    args.device_id = matched_devices[0][0]
    print(f"âœ… ä½¿ç”¨è£ç½® [{args.device_id}]ï¼š{matched_devices[0][1]}", flush=True)


# è¨­å®š log ç´€éŒ„
log_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger("ASR")
logger.setLevel(logging.INFO)
file_handler = logging.FileHandler(args.log_path, encoding='utf-8')
file_handler.setFormatter(log_formatter)
logger.addHandler(file_handler)

# é¸æ“‡è¨­å‚™
device = "cpu"# if args.use_cpu else ("cuda" if torch.cuda.is_available() else "cpu")

# è¼‰å…¥ Whisper æ¨¡å‹
try:
    logger.info(f"æ­£åœ¨è¼‰å…¥ Whisper æ¨¡å‹ '{args.model}' åˆ° {device.upper()}...")
    model = whisper.load_model(args.model , device=device)
    logger.info(f"æ¨¡å‹è¼‰å…¥æˆåŠŸï¼ä½¿ç”¨è¨­å‚™ï¼š{device}")
except Exception as e:
    logger.error(f"æ¨¡å‹è¼‰å…¥å¤±æ•—ï¼š{e}")
    sys.exit(1)

# é»‘åå–®è™•ç†
default_blacklist = "è¯·ä¸åç‚¹èµ,è®¢é˜…,è½¬å‘,æ‰“èµ,æ”¯æŒæ˜é•œä¸ç‚¹ç‚¹æ ç›®,è°¢è°¢å¤§å®¶,è¯·è®¢é˜…æˆ‘çš„é¢‘é“,æ¬¢è¿æ”¶çœ‹æœ¬æœŸèŠ‚ç›®,æ˜é•œä¸ç‚¹ç‚¹æ ç›®"
additional_blacklist = [s.strip() for s in args.blacklist.split(",") if s.strip()]
FORBIDDEN_PHRASES = list(set(default_blacklist.split(",") + additional_blacklist))
logger.info(f"é»‘åå–®é—œéµè©ï¼šå…±{len(FORBIDDEN_PHRASES)}å€‹é—œéµè©")

# éŸ³è¨Šåƒæ•¸
SAMPLERATE = 16000
FRAME_DURATION_MS = 30
FRAME_SIZE = int(SAMPLERATE * FRAME_DURATION_MS / 1000)
MIN_SPEECH_SECONDS = 0.5
MIN_VOLUME_THRESHOLD = 0.002
PARTIAL_INTERVAL = 2.0  # seconds between partial transcriptions
SLICE_DURATION = max(args.slice_duration, 1.0)
SLICE_LENGTH_SAMPLES = int(SAMPLERATE * SLICE_DURATION)
STEP_SAMPLES = SLICE_LENGTH_SAMPLES // 2

audio_q = queue.Queue()
vad = webrtcvad.Vad(1)

def print_json_output(obj):
    print(json.dumps(obj, ensure_ascii=False), flush=True)

def should_transcribe(audio_np: np.ndarray) -> bool:
    if len(audio_np) < SAMPLERATE * MIN_SPEECH_SECONDS:
        logger.info("èªéŸ³æ®µéçŸ­ï¼Œè·³éè¾¨è­˜")
        return False
    rms_volume = np.sqrt(np.mean(audio_np ** 2))
    if rms_volume < MIN_VOLUME_THRESHOLD:
        logger.info(f"éŸ³é‡éä½ï¼ˆ{rms_volume:.5f}ï¼‰ï¼Œè·³éè¾¨è­˜")
        return False
    return True

def is_forbidden(text: str) -> bool:
    return any(bad_phrase in text for bad_phrase in FORBIDDEN_PHRASES)

def callback(indata, frames, time, status):
    if status:
        logger.warning(f"éŸ³è¨Šç‹€æ…‹ï¼š{status}")
    audio_q.put(bytes(indata))

def listen(device_id: int = None):
    try:
        stream_args = {
            "samplerate": SAMPLERATE,
            "blocksize": FRAME_SIZE,
            "dtype": 'int16',
            "channels": 1,
            "callback": callback
        }
        if device_id is not None:
            stream_args["device"] = device_id

        with sd.RawInputStream(**stream_args):
            logger.info("é–‹å§‹èªéŸ³è¾¨è­˜ï¼Œè«‹é–‹å§‹èªªè©±...")
            speech_buffer = bytearray()
            triggered = False
            silence_counter = 0
            transcripts = []

            while True:
                data = audio_q.get()
                is_speech = vad.is_speech(data, SAMPLERATE)

                if is_speech:
                    speech_buffer.extend(data)
                    if not triggered:
                        triggered = True
                        silence_counter = 0
                        print("asr_start", flush=True)
                    else:
                        silence_counter = 0

                    while len(speech_buffer) // 2 >= SLICE_LENGTH_SAMPLES:
                        audio_slice = speech_buffer[:SLICE_LENGTH_SAMPLES * 2]
                        audio_np = np.frombuffer(audio_slice, dtype=np.int16).astype(np.float32) / 32768.0
                        if should_transcribe(audio_np):
                            try:
                                result = model.transcribe(
                                    audio_np,
                                    language='zh',
                                    temperature=0,
                                    no_speech_threshold=0.5
                                )
                                text = result.get("text", "").strip()
                                if text and not is_forbidden(text):
                                    logger.info(f"[å³æ™‚è¼¸å‡º] {text}")
                                    print_json_output({"partial": text})
                                    transcripts.append(text)
                            except Exception as e:
                                logger.error(f"Whisper å³æ™‚è¾¨è­˜éŒ¯èª¤ï¼š{e}")
                        speech_buffer = speech_buffer[STEP_SAMPLES * 2:]

                elif triggered:
                    speech_buffer.extend(data)
                    silence_counter += 1
                    if silence_counter > (int(500 / FRAME_DURATION_MS)):
                        while len(speech_buffer) // 2 >= MIN_SPEECH_SECONDS * SAMPLERATE:
                            slice_len = min(len(speech_buffer) // 2, SLICE_LENGTH_SAMPLES)
                            audio_slice = speech_buffer[:slice_len * 2]
                            audio_np = np.frombuffer(audio_slice, dtype=np.int16).astype(np.float32) / 32768.0
                            if should_transcribe(audio_np):
                                try:
                                    result = model.transcribe(
                                        audio_np,
                                        language='zh',
                                        temperature=0,
                                        no_speech_threshold=0.5
                                    )
                                    text = result.get("text", "").strip()
                                    if text and not is_forbidden(text):
                                        transcripts.append(text)
                                except Exception as e:
                                    logger.error(f"Whisper è¾¨è­˜éŒ¯èª¤ï¼š{e}")
                            speech_buffer = speech_buffer[STEP_SAMPLES * 2:] if len(speech_buffer) // 2 >= STEP_SAMPLES else bytearray()
                        final_text = "".join(transcripts)
                        if final_text:
                            logger.info(f"[è¾¨è­˜è¼¸å‡º] {final_text}")
                            print_json_output({"text": final_text})
                        else:
                            logger.info("å·²éæ¿¾å¹»è½è¼¸å‡ºæˆ–ç„¡æœ‰æ•ˆèªéŸ³")
                            print("asr_ignore", flush=True)
                        triggered = False
                        speech_buffer = bytearray()
                        transcripts = []
                        silence_counter = 0
    except Exception as e:
        logger.error(f"ç„¡æ³•é–‹å•ŸéŸ³è¨Šä¸²æµï¼š{e}")
        sys.exit(1)

if __name__ == "__main__":
    try:
        listen(device_id=args.device_id)
    except KeyboardInterrupt:
        logger.info("ç¨‹å¼å·²åœæ­¢")
